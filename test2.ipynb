{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Georgia, serif;\">**Twitter Sentiment Analysis** :Understanding Emotions in Tweets about Apple and Google products.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](twits.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem**: Using Sentiment Analysis to Improve Apple and Google Product Marketing Strategies \n",
    "\n",
    "The introduction of social media has completely changed how businesses interact with their consumers and the general public in today's connected society. While the digital age offers limitless possibilities for marketing and brand development, it also brings its own set of difficulties. One of these difficulties is the inability of enterprises to precisely gauge public opinion and feelings towards their goods or services.\n",
    "\n",
    "In the age of social media, organizations are acutely aware of the need to harness the wealth of sentiment and emotion data available on these platforms. However, they often struggle to do so effectively, given the unprecedented speed, diversity, and complexity of social media communication. The dynamic nature of the medium, the diverse and contextual language used, the rapid increase of emojis and visual content, the volume of noise, and ethical concerns all contribute to the challenge of gauging public sentiment and emotions. \n",
    "\n",
    "To overcome these challenges, organizations must invest in advanced sentiment analysis tools and technologies, develop cultural and linguistic expertise, and strike a balance between data-driven insights and ethical considerations. By doing so, they can unlock the valuable insights hidden within the social media storm and use them to inform strategic decisions, enhance products and services, and build stronger connections with their audience in this rapidly evolving digital landscape.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def remove_non_utf8(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "with open('data/judge_1377884607_tweet_product_company.csv', 'r', encoding='utf-8') as file:\n",
    "    cleaned_text = remove_non_utf8(file.read())\n",
    "\n",
    "df = pd.read_csv(io.StringIO(cleaned_text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_mapping = {'is_there_an_emotion_directed_at_a_brand_or_product': 'Sentiment'}\n",
    "# Rename the columns using the .rename() method\n",
    "df.rename(columns=column_name_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].fillna('N/A', inplace=True)\n",
    "df['tweet_text'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_brand(phrase):\n",
    "    if 'iPad' in phrase or 'iPhone' in phrase :\n",
    "        return 'Apple'\n",
    "    elif 'Other Apple product or service' in phrase or 'Apple' in phrase:\n",
    "        return 'Apple' \n",
    "    elif 'iPad or iPhone App' in phrase:\n",
    "        return 'Apple'       \n",
    "    elif 'Google' in phrase or 'Other Google product or service' in phrase:\n",
    "        return 'Google'\n",
    "    elif 'Android App' in phrase or 'Android' in phrase:\n",
    "        return 'Android'\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "df['brand'] = df['emotion_in_tweet_is_directed_at'].apply(assign_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize,TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def clean_and_preprocess_text(text):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # Convert tokens to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    # Remove mentions (words starting with '@') and URLs\n",
    "    tokens = [token for token in tokens if not token.startswith('@') and not token.startswith('http')]\n",
    "    # Remove punctuation and numbers using regular expressions\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # # Apply stemming using the Porter Stemmer\n",
    "    # stemmer = PorterStemmer()\n",
    "    # stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    cleaned_text = ' '.join(filtered_tokens) \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great stuff fri sxsw  marissa mayer  google   tim oreilly  tech books  conferences   matt mullenweg  wordpress '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_preprocess_text(df['tweet_text'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['tweet_text'].map(clean_and_preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>brand</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>@mention several people/events/sessions on iPh...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>several people  events  sessions iphone apps s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>RT @mention Just a friendly reminder for #SXSW...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>rt friendly reminder sxsw attendees  talk text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>Cause we so need another one RT @mention Googl...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>cause need another one rt google launch major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7414</th>\n",
       "      <td>Thanks girl! RT @mention Congrats to @mention ...</td>\n",
       "      <td>Other Apple product or service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>thanks girl  rt congrats winning last ipad cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>Marissa Mayer #sxsw Google &amp;quot;making smart ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Google</td>\n",
       "      <td>marissa mayer sxsw google  making smart phones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "7695  @mention several people/events/sessions on iPh...   \n",
       "5968  RT @mention Just a friendly reminder for #SXSW...   \n",
       "7726  Cause we so need another one RT @mention Googl...   \n",
       "7414  Thanks girl! RT @mention Congrats to @mention ...   \n",
       "2113  Marissa Mayer #sxsw Google &quot;making smart ...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  Sentiment   brand  \\\n",
       "7695                             N/A        2.0     N/A   \n",
       "5968                             N/A        2.0     N/A   \n",
       "7726                             N/A        2.0     N/A   \n",
       "7414  Other Apple product or service        1.0   Apple   \n",
       "2113                          Google        1.0  Google   \n",
       "\n",
       "                                         processed_text  \n",
       "7695  several people  events  sessions iphone apps s...  \n",
       "5968  rt friendly reminder sxsw attendees  talk text...  \n",
       "7726  cause need another one rt google launch major ...  \n",
       "7414  thanks girl  rt congrats winning last ipad cas...  \n",
       "2113  marissa mayer sxsw google  making smart phones...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping dictionary\n",
    "sentiment_mapping = {'No emotion toward brand or product': 2.0,\n",
    "                  'Positive emotion': 1.0, \n",
    "                  'Negative emotion': 0.0,\n",
    "                  'I can\\'t tell': 2.0}\n",
    "\n",
    "# Use the .map() method to map values in column 'A' to new values\n",
    "df['Sentiment'] = df['Sentiment'].map(sentiment_mapping)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#creating new df where sentiment is either positive or negative\n",
    "bi_tar = df[(df['Sentiment'] == 0)| (df['Sentiment'] == 1)]\n",
    "\n",
    "X = bi_tar['processed_text']\n",
    "y = bi_tar['Sentiment']\n",
    "\n",
    "X_train_bi, X_test_bi, y_train_bi, y_test_bi = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_tar = df.copy()\n",
    "X = multi_tar['processed_text']\n",
    "y = multi_tar['Sentiment']\n",
    "\n",
    "y_dummies = pd.get_dummies(y)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X, y_dummies, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def csr_Tfid_vect(X_train,X_test):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tf_idf_train = vectorizer.fit_transform(X_train)\n",
    "    tf_idf_test = vectorizer.transform(X_test)\n",
    "\n",
    "    tf_idf_train = csr_matrix(tf_idf_train)\n",
    "    tf_idf_test = csr_matrix(tf_idf_test)\n",
    "\n",
    "    return tf_idf_train,tf_idf_test\n",
    "\n",
    "X_tf_idf_train_bi,X_tf_idf_test_bi = csr_Tfid_vect(X_train_bi,X_test_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "def token_seq(feature):\n",
    "    tokenizer = text.Tokenizer(num_words=20000)\n",
    "    tokenizer.fit_on_texts(list(feature))\n",
    "    list_tokenized = tokenizer.texts_to_sequences(feature)\n",
    "    seq = sequence.pad_sequences(list_tokenized, maxlen=100)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       Normalized Frequency\n",
      "sxsw              0.0858       \n",
      "mention          0.06442       \n",
      "link             0.03821       \n",
      "rt               0.02743       \n",
      "ipad             0.02671       \n",
      "google            0.022        \n",
      "apple            0.01969       \n",
      "quot             0.01503       \n",
      "iphone           0.01414       \n",
      "store            0.01316       \n"
     ]
    }
   ],
   "source": [
    "from  nltk import FreqDist\n",
    "import string\n",
    "\n",
    "big_sentence = ' '.join(df['tweet_text'])\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "tweets_raw = nltk.regexp_tokenize(big_sentence, pattern)\n",
    "tweets_raw = [word.lower() for word in tweets_raw]\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "tweets_raw_stopped = [word for word in tweets_raw if word not in stopwords_list]\n",
    "tweets_freqdist = FreqDist(tweets_raw_stopped)\n",
    "total_word_count = sum(tweets_freqdist.values())\n",
    "tweets_freqdist_top_10 = tweets_freqdist.most_common(10)\n",
    "print(f'{\"Word\":10} Normalized Frequency')\n",
    "for word in tweets_freqdist_top_10:\n",
    "    normalized_frequency = word[1] / total_word_count\n",
    "    print(f'{word[0]:10} {normalized_frequency:^20.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('rt', 'mention'), 0.02666802617674867),\n",
       " (('sxsw', 'link'), 0.008527835968929014),\n",
       " (('link', 'sxsw'), 0.007656513598190615),\n",
       " (('sxsw', 'rt'), 0.006275374946701025),\n",
       " (('mention', 'mention'), 0.005728481118258838),\n",
       " (('mention', 'sxsw'), 0.005478207671344618),\n",
       " (('apple', 'store'), 0.005348436254426132),\n",
       " (('sxsw', 'mention'), 0.004755195491370201),\n",
       " (('link', 'rt'), 0.004718117943679205),\n",
       " (('mention', 'google'), 0.004356611853691997),\n",
       " (('social', 'network'), 0.0040970690198550265),\n",
       " (('new', 'social'), 0.003781909864481563),\n",
       " (('mention', 'rt'), 0.0031886691014256317),\n",
       " (('network', 'called'), 0.003021820136816151),\n",
       " (('store', 'sxsw'), 0.003021820136816151)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tweets_finder = BigramCollocationFinder.from_words(tweets_raw_stopped)\n",
    "tweets_scored = tweets_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "tweets_scored[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SXSW is best known for its conference and festivals that celebrate the convergence of tech, film, music, education, and culture.\n",
    "RT is the first Russian 24/7 English-language news channel which brings the Russian view on global news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724216, 978660)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "\n",
    "data = df['processed_text'].map(word_tokenize)\n",
    "model = Word2Vec(data, window=5, min_count=1, workers=4)\n",
    "model.train(data, total_examples=model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 0.6841039657592773),\n",
       " ('insertion', 0.6667062640190125),\n",
       " ('closing', 0.6543408036231995),\n",
       " ('amiss', 0.6521309018135071),\n",
       " ('motivator', 0.651293158531189),\n",
       " ('fascinated', 0.6509873867034912),\n",
       " ('south', 0.6475978493690491),\n",
       " ('asd', 0.6465953588485718),\n",
       " ('bart', 0.642691433429718),\n",
       " ('gtd', 0.6417152285575867)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv = model.wv\n",
    "wv.most_similar('sxsw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ringing', 0.3468869626522064),\n",
       " ('rows', 0.3398160934448242),\n",
       " ('captures', 0.32452720403671265),\n",
       " ('ure', 0.3209640681743622),\n",
       " ('snazzy', 0.3176901042461395),\n",
       " ('missoni', 0.2706739902496338),\n",
       " ('bt', 0.2581568956375122),\n",
       " ('cosby', 0.24320140480995178),\n",
       " ('disgusted', 0.18615488708019257),\n",
       " ('overthere', 0.18594567477703094)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(negative='sxsw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model**: Sentiment is either positive(1)or negative(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Random Forest', 0.8637869451193023),\n",
       " ('Support Vector Machine', 0.8568296515587877),\n",
       " ('Logistic Regression', 0.8443789251256308)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf =  Pipeline([('Random Forest', RandomForestClassifier(n_estimators=100, verbose=True))])\n",
    "svc = Pipeline([('Support Vector Machine', SVC())])\n",
    "lr = Pipeline([('Logistic Regression', LogisticRegression())])\n",
    "\n",
    "models = [('Random Forest', rf),\n",
    "          ('Support Vector Machine', svc),\n",
    "          ('Logistic Regression', lr)]\n",
    "\n",
    "scores = [(name, cross_val_score(model,X_tf_idf_train_bi, y_train_bi, cv=2).mean()) for name, model, in models]\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t =  token_seq(X_train_bi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8577 (33.50 KB)\n",
      "Trainable params: 8577 (33.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Dense(units=64, input_shape=(100,)))\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(32, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "77/77 [==============================] - 6s 24ms/step - loss: 177.9086 - accuracy: 0.6772 - val_loss: 64.8796 - val_accuracy: 0.8358\n",
      "Epoch 2/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 96.5561 - accuracy: 0.6772 - val_loss: 27.2956 - val_accuracy: 0.8139\n",
      "Epoch 3/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 64.7824 - accuracy: 0.7057 - val_loss: 13.9106 - val_accuracy: 0.7445\n",
      "Epoch 4/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 38.2868 - accuracy: 0.7171 - val_loss: 5.2441 - val_accuracy: 0.7810\n",
      "Epoch 5/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 21.6399 - accuracy: 0.7310 - val_loss: 2.3679 - val_accuracy: 0.8066\n",
      "Epoch 6/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 12.4318 - accuracy: 0.7680 - val_loss: 1.7024 - val_accuracy: 0.8248\n",
      "Epoch 7/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 7.7057 - accuracy: 0.7880 - val_loss: 1.4535 - val_accuracy: 0.8358\n",
      "Epoch 8/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 6.5498 - accuracy: 0.7945 - val_loss: 1.3538 - val_accuracy: 0.8358\n",
      "Epoch 9/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 4.5346 - accuracy: 0.8034 - val_loss: 1.3301 - val_accuracy: 0.8358\n",
      "Epoch 10/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 3.5777 - accuracy: 0.8083 - val_loss: 1.2836 - val_accuracy: 0.8358\n",
      "Epoch 11/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 2.7729 - accuracy: 0.8168 - val_loss: 1.2626 - val_accuracy: 0.8358\n",
      "Epoch 12/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 2.2740 - accuracy: 0.8217 - val_loss: 1.2585 - val_accuracy: 0.8358\n",
      "Epoch 13/15\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 2.2426 - accuracy: 0.8250 - val_loss: 1.2291 - val_accuracy: 0.8358\n",
      "Epoch 14/15\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 2.0753 - accuracy: 0.8299 - val_loss: 1.0264 - val_accuracy: 0.8358\n",
      "Epoch 15/15\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 1.7443 - accuracy: 0.8274 - val_loss: 0.8002 - val_accuracy: 0.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c44728d2a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_t, y_train_bi, epochs=15, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterated Model**: Sentiment is either positive(1),negative(0),No emotion toward brand or product(2) or Not clear(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_multi = token_seq(X_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "197/197 [==============================] - 6s 14ms/step - loss: 249.9910 - accuracy: 0.4556 - val_loss: 92.2088 - val_accuracy: 0.5100\n",
      "Epoch 2/15\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 92.4982 - accuracy: 0.4710 - val_loss: 47.2055 - val_accuracy: 0.5172\n",
      "Epoch 3/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 36.8549 - accuracy: 0.4844 - val_loss: 23.8372 - val_accuracy: 0.4785\n",
      "Epoch 4/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 17.2071 - accuracy: 0.4844 - val_loss: 12.3512 - val_accuracy: 0.4957\n",
      "Epoch 5/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 8.9667 - accuracy: 0.4939 - val_loss: 7.3707 - val_accuracy: 0.5616\n",
      "Epoch 6/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 4.7359 - accuracy: 0.5073 - val_loss: 4.2767 - val_accuracy: 0.5473\n",
      "Epoch 7/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 3.3787 - accuracy: 0.5027 - val_loss: 3.4541 - val_accuracy: 0.5330\n",
      "Epoch 8/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 2.3347 - accuracy: 0.5269 - val_loss: 2.7648 - val_accuracy: 0.5330\n",
      "Epoch 9/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 1.8310 - accuracy: 0.5403 - val_loss: 2.3912 - val_accuracy: 0.4986\n",
      "Epoch 10/15\n",
      "197/197 [==============================] - 1s 8ms/step - loss: 1.7227 - accuracy: 0.5433 - val_loss: 2.1566 - val_accuracy: 0.5186\n",
      "Epoch 11/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 1.5085 - accuracy: 0.5548 - val_loss: 1.8981 - val_accuracy: 0.5530\n",
      "Epoch 12/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 1.3432 - accuracy: 0.5532 - val_loss: 1.8098 - val_accuracy: 0.5244\n",
      "Epoch 13/15\n",
      "197/197 [==============================] - 1s 7ms/step - loss: 1.2716 - accuracy: 0.5465 - val_loss: 1.6229 - val_accuracy: 0.5473\n",
      "Epoch 14/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 1.1817 - accuracy: 0.5537 - val_loss: 1.5053 - val_accuracy: 0.5501\n",
      "Epoch 15/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 1.1197 - accuracy: 0.5647 - val_loss: 1.4776 - val_accuracy: 0.5358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c4470df3a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(64, activation='relu', input_shape=(100,)))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_2.fit(X_t_multi, y_train_multi, epochs=15, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [d for d in df['Sentiment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6728576404405773"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "r_f = Pipeline([('tfidf', TfidfVectorizer(max_features=1000)),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "\n",
    "scores = cross_val_score(r_f,df['processed_text'],c, cv=5).mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_features=1000)),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_features=1000)),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(max_features=1000)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f.fit(df['processed_text'],c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_new_column(value):\n",
    "    if value == 0.0:\n",
    "        return 'negative'\n",
    "    elif value == 1.0:\n",
    "        return 'positive'\n",
    "    elif value == 2.0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'unknown'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(filepath,tweet_column,dir_at,model):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        cleaned_text = remove_non_utf8(file.read())\n",
    "    df = pd.read_csv(io.StringIO(cleaned_text))\n",
    "\n",
    "    df[tweet_column].fillna('N/A', inplace=True)\n",
    "    df['processed_text'] = df[tweet_column].map(clean_and_preprocess_text)\n",
    "\n",
    "    df[dir_at].fillna('N/A', inplace=True)\n",
    "    df['brand'] = df[dir_at].apply(assign_brand)\n",
    "\n",
    "    data = df['processed_text']\n",
    "    pred = model.predict(data)\n",
    "\n",
    "    df['pred'] = pred\n",
    "    df['prediction'] = df['pred'].apply(map_to_new_column)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>brand</th>\n",
       "      <th>pred</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>#sxsw: @mention We think we control our identi...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>I can't tell</td>\n",
       "      <td>sxsw  think control identities facebook  googl...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>In the Google keynote, Marissa Meyer and some ...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>google keynote  marissa meyer guy demoing new ...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Talked to some great developers at the Android...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>talked great developers android meetup  lookin...</td>\n",
       "      <td>Android</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>@mention Hey Mark, no sleep for you at #sxsw! ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>hey mark  sleep sxsw  bring home shiny new ipa...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7744</th>\n",
       "      <td>Spending some time this morning resetting my a...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>spending time morning resetting android phone ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "2823  #sxsw: @mention We think we control our identi...   \n",
       "4715  In the Google keynote, Marissa Meyer and some ...   \n",
       "1055  Talked to some great developers at the Android...   \n",
       "3300  @mention Hey Mark, no sleep for you at #sxsw! ...   \n",
       "7744  Spending some time this morning resetting my a...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "2823                             N/A   \n",
       "4715                             N/A   \n",
       "1055                         Android   \n",
       "3300                            iPad   \n",
       "7744                         Android   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "2823                                       I can't tell   \n",
       "4715                 No emotion toward brand or product   \n",
       "1055                                   Positive emotion   \n",
       "3300                                   Positive emotion   \n",
       "7744                                   Negative emotion   \n",
       "\n",
       "                                         processed_text    brand  pred  \\\n",
       "2823  sxsw  think control identities facebook  googl...      N/A   2.0   \n",
       "4715  google keynote  marissa meyer guy demoing new ...      N/A   2.0   \n",
       "1055  talked great developers android meetup  lookin...  Android   1.0   \n",
       "3300  hey mark  sleep sxsw  bring home shiny new ipa...    Apple   1.0   \n",
       "7744  spending time morning resetting android phone ...  Android   2.0   \n",
       "\n",
       "     prediction  \n",
       "2823    neutral  \n",
       "4715    neutral  \n",
       "1055   positive  \n",
       "3300   positive  \n",
       "7744    neutral  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'data/judge_1377884607_tweet_product_company.csv'\n",
    "tweet_column = 'tweet_text'\n",
    "dir_at = 'emotion_in_tweet_is_directed_at'\n",
    "model = r_f\n",
    "\n",
    "pred_df = sentiment_predict(filepath,tweet_column,dir_at,model)\n",
    "pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                  26\n",
       "iPhone                20\n",
       "Apple                 19\n",
       "iPad or iPhone App    15\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive apple tweets\n",
    "apple_pos = pred_df[(pred_df['brand'] == 'Apple') & (pred_df['prediction'] == 'positive')]\n",
    "#negative apple tweets\n",
    "apple_neg = pred_df[(pred_df['brand'] == 'Apple') & (pred_df['prediction'] == 'negative')]\n",
    "apple_neg.emotion_in_tweet_is_directed_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Google                             10\n",
       "Other Google product or service     2\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive Google tweets\n",
    "Google_pos = pred_df[(pred_df['brand'] == 'Google') & (pred_df['prediction'] == 'positive')]\n",
    "#negative google tweets\n",
    "Google_neg = pred_df[(pred_df['brand'] == 'Google') & (pred_df['prediction'] == 'negative')]\n",
    "Google_neg.emotion_in_tweet_is_directed_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model_rf.pkl', 'wb') as file:\n",
    "    pickle.dump(r_f, file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
