{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Georgia, serif;\">**Twitter Sentiment Analysis** :Understanding Emotions in Tweets about Apple and Google products.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](twits.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem**: Using Sentiment Analysis to Improve Apple and Google Product Marketing Strategies \n",
    "\n",
    "The introduction of social media has completely changed how businesses interact with their consumers and the general public in today's connected society. While the digital age offers limitless possibilities for marketing and brand development, it also brings its own set of difficulties. One of these difficulties is the inability of enterprises to precisely gauge public opinion and feelings towards their goods or services.\n",
    "\n",
    "In the age of social media, organizations are acutely aware of the need to harness the wealth of sentiment and emotion data available on these platforms. However, they often struggle to do so effectively, given the unprecedented speed, diversity, and complexity of social media communication. The dynamic nature of the medium, the diverse and contextual language used, the rapid increase of emojis and visual content, the volume of noise, and ethical concerns all contribute to the challenge of gauging public sentiment and emotions. \n",
    "\n",
    "To overcome these challenges, organizations must invest in advanced sentiment analysis tools and technologies, develop cultural and linguistic expertise, and strike a balance between data-driven insights and ethical considerations. By doing so, they can unlock the valuable insights hidden within the social media storm and use them to inform strategic decisions, enhance products and services, and build stronger connections with their audience in this rapidly evolving digital landscape.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def remove_non_utf8(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "with open('data/judge_1377884607_tweet_product_company.csv', 'r', encoding='utf-8') as file:\n",
    "    cleaned_text = remove_non_utf8(file.read())\n",
    "\n",
    "df = pd.read_csv(io.StringIO(cleaned_text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Conan doc, CDR Radio, Android party, NPR shind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>Hot Pot from Google for mobile maps is a 'very...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>If you're coming to #SXSW be sure to download ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>RT @mention Questioner at #sxsw just said &amp;quo...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>someone started an #austin @PartnerHub group i...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "1337  Conan doc, CDR Radio, Android party, NPR shind...   \n",
       "7432  Hot Pot from Google for mobile maps is a 'very...   \n",
       "395   If you're coming to #SXSW be sure to download ...   \n",
       "6230  RT @mention Questioner at #sxsw just said &quo...   \n",
       "27    someone started an #austin @PartnerHub group i...   \n",
       "\n",
       "      emotion_in_tweet_is_directed_at                           Sentiment  \n",
       "1337                              NaN  No emotion toward brand or product  \n",
       "7432  Other Google product or service                    Positive emotion  \n",
       "395                iPad or iPhone App                    Positive emotion  \n",
       "6230                           Google                    Positive emotion  \n",
       "27    Other Google product or service                    Positive emotion  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name_mapping = {'is_there_an_emotion_directed_at_a_brand_or_product': 'Sentiment'}\n",
    "# Rename the columns using the .rename() method\n",
    "df.rename(columns=column_name_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].fillna('N/A', inplace=True)\n",
    "df['tweet_text'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>RT @mention  Happy Woman's Day! Make love, not...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>#Apple, #Google, #Intel and Others Go Gaga for...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>I can't tell</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>Yes, the rumors are true. Come play with @ment...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>RT @mention Our #sxsw app is now on #android :...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>Thank heavens for nice travelers. Got a iPhone...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "5109  RT @mention  Happy Woman's Day! Make love, not...   \n",
       "3183  #Apple, #Google, #Intel and Others Go Gaga for...   \n",
       "7512  Yes, the rumors are true. Come play with @ment...   \n",
       "6190  RT @mention Our #sxsw app is now on #android :...   \n",
       "8417  Thank heavens for nice travelers. Got a iPhone...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at                           Sentiment  \\\n",
       "5109                             N/A  No emotion toward brand or product   \n",
       "3183                             N/A                        I can't tell   \n",
       "7512                             N/A                    Positive emotion   \n",
       "6190                     Android App                    Positive emotion   \n",
       "8417                          iPhone                    Positive emotion   \n",
       "\n",
       "        brand  \n",
       "5109      N/A  \n",
       "3183      N/A  \n",
       "7512      N/A  \n",
       "6190  Android  \n",
       "8417    Apple  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_brand(phrase):\n",
    "    if 'iPad' in phrase or 'iPhone' in phrase :\n",
    "        return 'Apple'\n",
    "    elif 'Other Apple product or service' in phrase or 'Apple' in phrase:\n",
    "        return 'Apple' \n",
    "    elif 'iPad or iPhone App' in phrase:\n",
    "        return 'Apple'       \n",
    "    elif 'Google' in phrase or 'Other Google product or service' in phrase:\n",
    "        return 'Google'\n",
    "    elif 'Android App' in phrase or 'Android' in phrase:\n",
    "        return 'Android'\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "df['brand'] = df['emotion_in_tweet_is_directed_at'].apply(assign_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize,TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def clean_and_preprocess_text(text):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # Convert tokens to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    # Remove mentions (words starting with '@') and URLs\n",
    "    tokens = [token for token in tokens if not token.startswith('@') and not token.startswith('http')]\n",
    "    # Remove punctuation and numbers using regular expressions\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Apply stemming using the Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    cleaned_text = ' '.join(stemmed_tokens) \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great stuff fri sxsw  marissa mayer  googl   tim oreilli  tech book  confer   matt mullenweg  wordpress '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_preprocess_text(df['tweet_text'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>brand</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>RT @mention If you were able to afford to atte...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>N/A</td>\n",
       "      <td>rt abl afford attend sxsw buy ipad today  cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>iPad giveaway for using @mention at #sxsw {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>ipad giveaway use sxsw  link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>At &amp;quot;Your Mom Has an iPad&amp;quot; session #y...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>N/A</td>\n",
       "      <td>mom ipad  session yourmom sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>#sxsw #enchantment: @mention &amp;quot;It's like s...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>N/A</td>\n",
       "      <td>sxsw enchant   like say  pleas dont regist  go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>@mention I want that iPad case! #sxswbuffalo #...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>want ipad case  sxswbuffalo sxsw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "5873  RT @mention If you were able to afford to atte...   \n",
       "2097   iPad giveaway for using @mention at #sxsw {link}   \n",
       "8704  At &quot;Your Mom Has an iPad&quot; session #y...   \n",
       "2237  #sxsw #enchantment: @mention &quot;It's like s...   \n",
       "3392  @mention I want that iPad case! #sxswbuffalo #...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at                           Sentiment  \\\n",
       "5873                             N/A  No emotion toward brand or product   \n",
       "2097                            iPad                    Positive emotion   \n",
       "8704                             N/A  No emotion toward brand or product   \n",
       "2237                             N/A  No emotion toward brand or product   \n",
       "3392                            iPad                    Positive emotion   \n",
       "\n",
       "      brand                                     processed_text  \n",
       "5873    N/A  rt abl afford attend sxsw buy ipad today  cons...  \n",
       "2097  Apple                      ipad giveaway use sxsw  link   \n",
       "8704    N/A                     mom ipad  session yourmom sxsw  \n",
       "2237    N/A  sxsw enchant   like say  pleas dont regist  go...  \n",
       "3392  Apple                   want ipad case  sxswbuffalo sxsw  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['tweet_text'].map(clean_and_preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>brand</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>You finally get everyone to buy in to Facebook...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Google</td>\n",
       "      <td>final get everyon buy facebook googl introduc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>Interesting debate on jcpenney tactics on site...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>interest debat jcpenney tactic site show irrel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>After... Come visit Milyoni we are at Booth, 1...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>come visit milyoni booth   right big googl si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>RT @mention Android may be gaining market shar...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>rt android may gain market share  youd never k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>And @mention opens with some tech talk on the ...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>open tech talk appl store whore pc  right crow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "4041  You finally get everyone to buy in to Facebook...   \n",
       "4390  Interesting debate on jcpenney tactics on site...   \n",
       "2280  After... Come visit Milyoni we are at Booth, 1...   \n",
       "5160  RT @mention Android may be gaining market shar...   \n",
       "3600  And @mention opens with some tech talk on the ...   \n",
       "\n",
       "      emotion_in_tweet_is_directed_at  Sentiment   brand  \\\n",
       "4041  Other Google product or service        0.0  Google   \n",
       "4390                              N/A        2.0     N/A   \n",
       "2280                              N/A        2.0     N/A   \n",
       "5160                              N/A        2.0     N/A   \n",
       "3600                              N/A        2.0     N/A   \n",
       "\n",
       "                                         processed_text  \n",
       "4041  final get everyon buy facebook googl introduc ...  \n",
       "4390  interest debat jcpenney tactic site show irrel...  \n",
       "2280   come visit milyoni booth   right big googl si...  \n",
       "5160  rt android may gain market share  youd never k...  \n",
       "3600  open tech talk appl store whore pc  right crow...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping dictionary\n",
    "sentiment_mapping = {'No emotion toward brand or product': 2.0,\n",
    "                  'Positive emotion': 1.0, \n",
    "                  'Negative emotion': 0.0,\n",
    "                  'I can\\'t tell': 2.0}\n",
    "\n",
    "# Use the .map() method to map values in column 'A' to new values\n",
    "df['Sentiment'] = df['Sentiment'].map(sentiment_mapping)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#creating new df where sentiment is either positive or negative\n",
    "bi_tar = df[(df['Sentiment'] == 0)| (df['Sentiment'] == 1)]\n",
    "\n",
    "X = bi_tar['processed_text']\n",
    "y = bi_tar['Sentiment']\n",
    "\n",
    "X_train_bi, X_test_bi, y_train_bi, y_test_bi = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_tar = df.copy()\n",
    "X = multi_tar['processed_text']\n",
    "y = multi_tar['Sentiment']\n",
    "\n",
    "y_dummies = pd.get_dummies(y)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X, y_dummies, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def csr_Tfid_vect(X_train,X_test):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tf_idf_train = vectorizer.fit_transform(X_train)\n",
    "    tf_idf_test = vectorizer.transform(X_test)\n",
    "\n",
    "    tf_idf_train = csr_matrix(tf_idf_train)\n",
    "    tf_idf_test = csr_matrix(tf_idf_test)\n",
    "\n",
    "    return tf_idf_train,tf_idf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf_idf_train_bi,X_tf_idf_test_bi = csr_Tfid_vect(X_train_bi,X_test_bi)\n",
    "\n",
    "X_tf_idf_train_multi,X_tf_idf_test_multi = csr_Tfid_vect(X_train_multi,X_test_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "def token_seq(feature):\n",
    "    tokenizer = text.Tokenizer(num_words=20000)\n",
    "    tokenizer.fit_on_texts(list(feature))\n",
    "    list_tokenized = tokenizer.texts_to_sequences(feature)\n",
    "    seq = sequence.pad_sequences(list_tokenized, maxlen=100)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sxsw', 9256),\n",
       " ('mention', 6950),\n",
       " ('link', 4122),\n",
       " ('rt', 2959),\n",
       " ('ipad', 2882),\n",
       " ('google', 2373),\n",
       " ('apple', 2124),\n",
       " ('quot', 1621),\n",
       " ('iphone', 1525),\n",
       " ('store', 1420)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  nltk import FreqDist\n",
    "import string\n",
    "\n",
    "big_sentence = ' '.join(df['tweet_text'])\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "tweets_raw = nltk.regexp_tokenize(big_sentence, pattern)\n",
    "tweets_raw = [word.lower() for word in tweets_raw]\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "tweets_raw_stopped = [word for word in tweets_raw if word not in stopwords_list]\n",
    "tweets_freqdist = FreqDist(tweets_raw_stopped)\n",
    "tweets_freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       Normalized Frequency\n",
      "sxsw              0.0858       \n",
      "mention          0.06442       \n",
      "link             0.03821       \n",
      "rt               0.02743       \n",
      "ipad             0.02671       \n",
      "google            0.022        \n",
      "apple            0.01969       \n",
      "quot             0.01503       \n",
      "iphone           0.01414       \n",
      "store            0.01316       \n"
     ]
    }
   ],
   "source": [
    "total_word_count = sum(tweets_freqdist.values())\n",
    "tweets_freqdist_top_10 = tweets_freqdist.most_common(10)\n",
    "print(f'{\"Word\":10} Normalized Frequency')\n",
    "for word in tweets_freqdist_top_10:\n",
    "    normalized_frequency = word[1] / total_word_count\n",
    "    print(f'{word[0]:10} {normalized_frequency:^20.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('rt', 'mention'), 0.02666802617674867),\n",
       " (('sxsw', 'link'), 0.008527835968929014),\n",
       " (('link', 'sxsw'), 0.007656513598190615),\n",
       " (('sxsw', 'rt'), 0.006275374946701025),\n",
       " (('mention', 'mention'), 0.005728481118258838),\n",
       " (('mention', 'sxsw'), 0.005478207671344618),\n",
       " (('apple', 'store'), 0.005348436254426132),\n",
       " (('sxsw', 'mention'), 0.004755195491370201),\n",
       " (('link', 'rt'), 0.004718117943679205),\n",
       " (('mention', 'google'), 0.004356611853691997),\n",
       " (('social', 'network'), 0.0040970690198550265),\n",
       " (('new', 'social'), 0.003781909864481563),\n",
       " (('mention', 'rt'), 0.0031886691014256317),\n",
       " (('network', 'called'), 0.003021820136816151),\n",
       " (('store', 'sxsw'), 0.003021820136816151)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tweets_finder = BigramCollocationFinder.from_words(tweets_raw_stopped)\n",
    "tweets_scored = tweets_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "tweets_scored[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SXSW is best known for its conference and festivals that celebrate the convergence of tech, film, music, education, and culture.\n",
    "RT is the first Russian 24/7 English-language news channel which brings the Russian view on global news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model**: Sentiment is either positive(1)or negative(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Random Forest', 0.8623222799650325),\n",
       " ('Support Vector Machine', 0.8582943167130577),\n",
       " ('Logistic Regression', 0.8447452254919312)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf =  Pipeline([('Random Forest', RandomForestClassifier(n_estimators=100, verbose=True))])\n",
    "svc = Pipeline([('Support Vector Machine', SVC())])\n",
    "lr = Pipeline([('Logistic Regression', LogisticRegression())])\n",
    "\n",
    "models = [('Random Forest', rf),\n",
    "          ('Support Vector Machine', svc),\n",
    "          ('Logistic Regression', lr)]\n",
    "\n",
    "scores = [(name, cross_val_score(model,X_tf_idf_train_bi, y_train_bi, cv=2).mean()) for name, model, in models]\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t =  token_seq(X_train_bi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8577 (33.50 KB)\n",
      "Trainable params: 8577 (33.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Dense(units=64, input_shape=(100,)))\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(32, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 17ms/step - loss: 87.5949 - accuracy: 0.6695 - val_loss: 19.5754 - val_accuracy: 0.7956\n",
      "Epoch 2/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 45.0084 - accuracy: 0.6956 - val_loss: 8.2345 - val_accuracy: 0.7263\n",
      "Epoch 3/15\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 27.6558 - accuracy: 0.6943 - val_loss: 3.5227 - val_accuracy: 0.7920\n",
      "Epoch 4/15\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 13.0241 - accuracy: 0.7310 - val_loss: 2.1928 - val_accuracy: 0.8212\n",
      "Epoch 5/15\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 7.6960 - accuracy: 0.7603 - val_loss: 1.5647 - val_accuracy: 0.8358\n",
      "Epoch 6/15\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 4.3894 - accuracy: 0.7745 - val_loss: 1.3895 - val_accuracy: 0.8029\n",
      "Epoch 7/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 3.6947 - accuracy: 0.7880 - val_loss: 1.1107 - val_accuracy: 0.8175\n",
      "Epoch 8/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 2.4112 - accuracy: 0.7928 - val_loss: 1.0744 - val_accuracy: 0.8358\n",
      "Epoch 9/15\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 2.1449 - accuracy: 0.8217 - val_loss: 0.9825 - val_accuracy: 0.8285\n",
      "Epoch 10/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 2.4011 - accuracy: 0.8087 - val_loss: 1.0294 - val_accuracy: 0.8285\n",
      "Epoch 11/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 1.3492 - accuracy: 0.8152 - val_loss: 0.9951 - val_accuracy: 0.8358\n",
      "Epoch 12/15\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 1.3740 - accuracy: 0.8116 - val_loss: 0.8581 - val_accuracy: 0.8358\n",
      "Epoch 13/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 1.0865 - accuracy: 0.8270 - val_loss: 0.8002 - val_accuracy: 0.8358\n",
      "Epoch 14/15\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 1.2658 - accuracy: 0.8225 - val_loss: 0.8030 - val_accuracy: 0.8358\n",
      "Epoch 15/15\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 1.0277 - accuracy: 0.8246 - val_loss: 0.7602 - val_accuracy: 0.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x199c652e7d0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_t, y_train_bi, epochs=15, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterated Model**: Sentiment is either positive(1),negative(0),No emotion toward brand or product(2) or Not clear(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_multi = token_seq(X_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "197/197 [==============================] - 5s 11ms/step - loss: 206.0351 - accuracy: 0.4414 - val_loss: 58.4465 - val_accuracy: 0.5186\n",
      "Epoch 2/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 78.7770 - accuracy: 0.4621 - val_loss: 36.4901 - val_accuracy: 0.5573\n",
      "Epoch 3/15\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 32.9272 - accuracy: 0.4626 - val_loss: 14.4686 - val_accuracy: 0.5458\n",
      "Epoch 4/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 13.8755 - accuracy: 0.4863 - val_loss: 6.7932 - val_accuracy: 0.5387\n",
      "Epoch 5/15\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 6.0164 - accuracy: 0.4994 - val_loss: 3.9201 - val_accuracy: 0.5387\n",
      "Epoch 6/15\n",
      "197/197 [==============================] - 2s 8ms/step - loss: 3.5619 - accuracy: 0.5245 - val_loss: 2.7821 - val_accuracy: 0.5587\n",
      "Epoch 7/15\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 2.4239 - accuracy: 0.5325 - val_loss: 2.1739 - val_accuracy: 0.5587\n",
      "Epoch 8/15\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.7006 - accuracy: 0.5452 - val_loss: 1.8748 - val_accuracy: 0.5573\n",
      "Epoch 9/15\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.6411 - accuracy: 0.5448 - val_loss: 1.5898 - val_accuracy: 0.5401\n",
      "Epoch 10/15\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.4519 - accuracy: 0.5586 - val_loss: 1.5046 - val_accuracy: 0.5645\n",
      "Epoch 11/15\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.3277 - accuracy: 0.5526 - val_loss: 1.5008 - val_accuracy: 0.5344\n",
      "Epoch 12/15\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.2771 - accuracy: 0.5628 - val_loss: 1.5134 - val_accuracy: 0.5473\n",
      "Epoch 13/15\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 1.1701 - accuracy: 0.5628 - val_loss: 1.3764 - val_accuracy: 0.5731\n",
      "Epoch 14/15\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.1295 - accuracy: 0.5629 - val_loss: 1.3016 - val_accuracy: 0.5559\n",
      "Epoch 15/15\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.0785 - accuracy: 0.5637 - val_loss: 1.3143 - val_accuracy: 0.5659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x199c810b3d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(64, activation='relu', input_shape=(100,)))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_2.fit(X_t_multi, y_train_multi, epochs=15, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load your GloVe model\n",
    "glove_model = KeyedVectors.load_word2vec_format('path_to_glove_file', binary=False)\n",
    "\n",
    "# Create document-level embeddings using GloVe\n",
    "def document_vectorizer(text, model):\n",
    "    words = text.split()\n",
    "    vectors = [model[word] if word in model else np.zeros(model.vector_size) for word in words]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "# Create GloVe-based embeddings for each text\n",
    "document_embeddings = [document_vectorizer(text, glove_model) for text in X_train_multi]\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "X = np.array(document_embeddings)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train_multi, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classification model (e.g., Logistic Regression)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate your model on the test set\n",
    "accuracy = classifier.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
